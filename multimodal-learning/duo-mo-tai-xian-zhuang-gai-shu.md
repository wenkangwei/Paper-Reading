# 多模态现状概述

## 什么是多模态

多模态学习试图对不同模态的数据组合进行建模，这在现实世界的应用中经常出现。联合数据的一个例子是将文本（通常表示为离散的字数向量）与由像素强度和注释标签组成的成像数据相结合。由于这些模式具有根本上不同的统计属性，将它们结合在一起是不容易的，这就是为什么需要专门的建模策略和算法。

很多模型/算法已经实现了对某类数据的检索和分类，例如图像或文本（与机器互动的人类可以提取图片形式的图像和可能是任何信息的文本等）。然而，数据通常带有不同的模式（它是指一个系统的组成部分可能被分离或组合的程度），这些模式携带不同的信息。例如，为一张图片添加标题以传达该图片未呈现的信息是非常常见的。同样地，有时用图像来描述从文本中可能不明显的信息也是比较直接的。因此，如果一些不同的词出现在类似的图像中，这些词很可能是用来描述同一事物的。反之，如果一些词用在不同的图像中，这些图像可能代表同一个物体。因此，邀请一个能够共同代表信息的新模型是很重要的，这样的模型可以捕捉到不同模式之间的相关结构。此外，它还应该能够恢复缺失的模式，例如，根据文本描述预测可能的图像对象。多模态深度波尔兹曼机模型满足了上述目的。



## 多模态常见问题

### 1、多模态表征(Representation)

单模态的表征负责将信息表示为计算机可以处理的数值向量或者进一步抽象为更高层的特征向量.

而多模态表征是指通过利用多模态之间的互补性，剔除模态间的冗余性，从而学习到更好的特征表示。

多模态表征常见表达方式有2种：

1. joint representation联合表征：用于把所有不同模态向量投影到相同的空间， 用于捕捉不同模态之间互补信息， 并合并得到向量xm=f(x1, x2,...) 用于任务的预测, 比如推荐预测打分之类任务
2. coordinate representation协作表征：把不同模态信息经过映射到coordinate space协作空间， 得到各个模态各自的表征。但是对映射后表征做了限制， 比如让映射后的表征f(x1), g(x2)向量要尽可能相似. 一个典型的例子是CLIP模型, 它让一只狗的图片和文本描述分别Image encoder和Text Encoder 得到图片和文本向量， 然后让它们通过相似度关联起来

<figure><img src="../.gitbook/assets/image (4) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 2、多模态信息对齐(Alignment)

多模态对齐是指从2种或多种模态的子元素之间识别出来， 比如视频中的片段和这个视频片段的描述识别出来，

![](<../.gitbook/assets/image (1) (1) (1) (1).png>)&#x20;

常见的对齐方法分2种:

**显性识别：** 直接通过把2种或以上的不同模态的子元素通过相似度进行衡量，这种对齐方式又分2种：

* **无监督对齐**：给定两个模态的数据作为输入，希望模型实现子元素的对齐，但是训练数据没有“对齐结果”的标注，模型需要同时学习相似度度量和对齐方式。
* **有监督对齐**：有监督方法存在标注，可训练模型学习相似度度量

**隐性识别:** 不会直接把多个模态的元素关联起来， 而是在模型训练过程中隐性慢慢自动学起来，这种方法能在许多任务中有更好的表现，包括语音识别、机器翻译、媒体描述和视觉问题回答。一个例子是NLP的翻译任务中不同语言文字之间的关联是通过神经网络进行自动学习对齐的。



### 3、模态融合(Fusion)

**多模态融合是结合来自两个或多个模态的信息**来执行预测。例如，对于视听语音识别，将嘴唇运动的视觉描述与语音信号融合以预测口语。来自不同模态的信息可能具有不同的预测能力和噪声拓扑，并且可能在至少一种模态中丢失数据。

**Model-Free与模型无关的融合方法**

1. early fusion : 在特征数据进入预测模型之前提前把多模态数据(通常是向量) 进行融合
   1. 优点：多个模态信息提前能控制预测模型的复杂度， 只需训练一个模型
   2. 缺点：不同模态数据进行融合拼接一般维度很大，比如每个模态以512维度向量存储那么直接拼接后向量会很大&#x20;
2. late fusion：不同模态有自己的预测模型， 预测模型各自打分预测的结果融合。 model ensemble的思想
   1. 优点： 每个模态的信息和模型相互独立， 有些模态信息或者模型有问题缺失不会严重影响最终预测效果
   2. 缺点：这个方法假设每个模态相互独立，没有充分利用模态之间相关性
3. hybrid fusion：把early fusion和late fusion同时结合着用
   1. 优点：可以灵活使用early fusion和late fusion的优点， 可以调整模型结构复杂度， 也可考虑不同模态之间的相关性。



<figure><img src="../.gitbook/assets/image (2) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

**Model-Base**

**Model-base 的模态融合方法基本像使用深度学习DNN，或者kernel模型或者像是马尔科夫链图概率模型**

* **Deep Neural Networks**：神经网络进行端到端的训练，使用LSTM、卷积层、注意力层、门机制、双线性融合等设计序列数据或图像数据的复杂交互。
* **Multiple Kernel learning**：多核学习（将不同的核用于不同的数据模态/视图）
* **Graphical models**：利用隐马尔可夫模型或贝叶斯网络建模数据的联合概率分布(生成式)或条件概率(判别式)



### 4、翻译 (Translation)

translation 问题关注怎么把一个模态形式转换到另外一个模态。

常见任务类型：

* **机器翻译（Machine Translation）**：将输入的语言A（即时）翻译为另一种语言B。类似的还有唇读（Lip Reading）和语音翻译 （Speech Translation），分别将唇部视觉和语音信息转换为文本信息。
* **图片描述（Image captioning) 或者视频描述（Video captioning)**： 对给定的图片/视频形成一段文字描述，以表达图片/视频的内容。
* **语音合成（Speech Synthesis）**：根据输入的文本信息，自动合成一段语音信号。

解决翻译问题的常见方法：

* **基于实例方法**
  * 举个例子就是在给定一个单词（实例）x, 然后在词典里面找出和x最相似的单词xi, 然后在词典里找xi对应的翻译描述y。 这个词典一般可以有多个不同模态， 模态越多，给到的信息越充足效果一般越好。
* **基于模型驱动方法**
  * 在字典上训练一个翻译模型，然后使用该模型进行翻译。

<figure><img src="../.gitbook/assets/image (3) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

多模态翻译任务的难点：

翻译的结果很难评估。语音识别等任务只有一个正确的翻译，而语音合成和媒体描述等任务则没有。有时，就像在语言翻译中，多重答案是正确的，决定哪个翻译更好往往是主观的。

* **人工评价**是最理想的评估，但是耗时耗钱，且需要多样化打分人群的背景以避免偏见。
* **自动化指标**是视觉描述领域常用的替代方法，包括BLEU，Meteor，CIDEr，ROUGE等，但它们被证实与人的评价相关性较弱。
* **基于检索的评估**和**弱化任务**(例如：将图像描述中一对多映射简化为VQA中一对一的映射)也是解决评估困境的手段

### 5、协同训练（Co-learning）

这个问题考虑怎么把多模态模型中一个模态的知识帮助其他模态的学习

parallel: 并行学习中数据集里面每个样本实例都有一一对应的模态信息， 同时学习多个模态

non-parallel: 非并行学习中不同模态的数据集可以分开多个， 样本实例的模态信息不一定一定对应。 一个例子是NLP, CV产出的文本图片向量就是用独立模态训练， 然后这些向量用到推荐模型里描述商品。

hybrid: 实例的信息和知识通过第三方数据集把不同模态数据集关联起来

<figure><img src="../.gitbook/assets/image (4) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>









## 参考

[https://arxiv.org/pdf/1705.09406](https://arxiv.org/pdf/1705.09406)

Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning[https://arxiv.org/pdf/2203.02053.pdf](https://arxiv.org/pdf/2203.02053.pdf)

[2302.04473v1.pdf](file:///D:/%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0/Papers/2302.04473v1.pdf)

{% embed url="https://zhuanlan.zhihu.com/p/434452481" %}

{% embed url="https://imzhanghao.com/2022/10/27/multimodal-learning/#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99" %}



